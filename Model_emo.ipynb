{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LASYA\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:72: UserWarning: h5py is running against HDF5 1.10.2 when it was built against 1.10.3, this may cause problems\n",
      "  '{0}.{1}.{2}'.format(*version.hdf5_built_version_tuple)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_model(image_x, image_y):\n",
    "    num_of_classes = 12\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (5, 5), input_shape=(image_x, image_y, 1), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
    "    model.add(Conv2D(64, (5, 5), activation='sigmoid'))\n",
    "    model.add(MaxPooling2D(pool_size=(5, 5), strides=(5, 5), padding='same'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(0.6))\n",
    "    model.add(Dense(num_of_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    filepath = \"emojinator.h5\"\n",
    "    checkpoint1 = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint1]\n",
    "\n",
    "    return model, callbacks_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"train_foo.csv\")\n",
    "dataset = np.array(data)\n",
    "np.random.shuffle(dataset)\n",
    "X = dataset\n",
    "Y = dataset\n",
    "X = X[:, 1:2501]\n",
    "Y = Y[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[0:12000, :]\n",
    "X_train = X_train / 255.\n",
    "X_test = X[12000:13201, :]\n",
    "X_test = X_test / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape\n",
    "Y = Y.reshape(Y.shape[0], 1)\n",
    "Y_train = Y[0:12000, :]\n",
    "Y_train = Y_train.T\n",
    "Y_test = Y[12000:13201, :]\n",
    "Y_test = Y_test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 12000\n",
      "number of test examples = 1201\n",
      "X_train shape: (12000, 2500)\n",
      "Y_train shape: (1, 12000)\n",
      "X_test shape: (1201, 2500)\n",
      "Y_test shape: (1, 1201)\n"
     ]
    }
   ],
   "source": [
    "print(\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print(\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print(\"X_train shape: \" + str(X_train.shape))\n",
    "print(\"Y_train shape: \" + str(Y_train.shape))\n",
    "print(\"X_test shape: \" + str(X_test.shape))\n",
    "print(\"Y_test shape: \" + str(Y_test.shape))\n",
    "image_x = 50\n",
    "image_y = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (12000, 50, 50, 1)\n",
      "X_test shape: (1201, 50, 50, 1)\n"
     ]
    }
   ],
   "source": [
    "train_y = np_utils.to_categorical(Y_train)\n",
    "test_y = np_utils.to_categorical(Y_test)\n",
    "train_y = train_y.reshape(train_y.shape[1], train_y.shape[2])\n",
    "test_y = test_y.reshape(test_y.shape[1], test_y.shape[2])\n",
    "X_train = X_train.reshape(X_train.shape[0], 50, 50, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 50, 50, 1)\n",
    "print(\"X_train shape: \" + str(X_train.shape))\n",
    "print(\"X_test shape: \" + str(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0816 15:33:11.008478  2704 deprecation_wrapper.py:119] From C:\\Users\\LASYA\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0816 15:33:12.491786  2704 deprecation_wrapper.py:119] From C:\\Users\\LASYA\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0816 15:33:12.781532  2704 deprecation_wrapper.py:119] From C:\\Users\\LASYA\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0816 15:33:13.033196  2704 deprecation_wrapper.py:119] From C:\\Users\\LASYA\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0816 15:33:13.351627  2704 deprecation_wrapper.py:119] From C:\\Users\\LASYA\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0816 15:33:13.375473  2704 deprecation.py:506] From C:\\Users\\LASYA\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0816 15:33:13.381454  2704 nn_ops.py:4224] Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "W0816 15:33:13.477682  2704 deprecation_wrapper.py:119] From C:\\Users\\LASYA\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0816 15:33:13.591489  2704 deprecation_wrapper.py:119] From C:\\Users\\LASYA\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0816 15:33:14.050952  2704 deprecation.py:323] From C:\\Users\\LASYA\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12000 samples, validate on 1201 samples\n",
      "Epoch 1/10\n",
      "12000/12000 [==============================] - 70s 6ms/step - loss: 0.5237 - acc: 0.8426 - val_loss: 0.0061 - val_acc: 0.9975\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.99750, saving model to emojinator.h5\n",
      "Epoch 2/10\n",
      "12000/12000 [==============================] - 55s 5ms/step - loss: 0.0089 - acc: 0.9979 - val_loss: 5.5873e-04 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.99750 to 1.00000, saving model to emojinator.h5\n",
      "Epoch 3/10\n",
      "12000/12000 [==============================] - 57s 5ms/step - loss: 0.0032 - acc: 0.9994 - val_loss: 1.2900e-04 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 1.00000\n",
      "Epoch 4/10\n",
      "12000/12000 [==============================] - 60s 5ms/step - loss: 0.0026 - acc: 0.9993 - val_loss: 8.3555e-04 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 1.00000\n",
      "Epoch 5/10\n",
      "12000/12000 [==============================] - 50s 4ms/step - loss: 0.0016 - acc: 0.9997 - val_loss: 2.9049e-05 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 1.00000\n",
      "Epoch 6/10\n",
      "12000/12000 [==============================] - 58s 5ms/step - loss: 3.3581e-04 - acc: 1.0000 - val_loss: 2.1045e-05 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 1.00000\n",
      "Epoch 7/10\n",
      "12000/12000 [==============================] - 62s 5ms/step - loss: 2.8334e-04 - acc: 1.0000 - val_loss: 1.2367e-05 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 1.00000\n",
      "Epoch 8/10\n",
      "12000/12000 [==============================] - 53s 4ms/step - loss: 6.5084e-04 - acc: 0.9999 - val_loss: 7.5096e-05 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 1.00000\n",
      "Epoch 9/10\n",
      "12000/12000 [==============================] - 52s 4ms/step - loss: 0.0021 - acc: 0.9996 - val_loss: 3.4206e-05 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 1.00000\n",
      "Epoch 10/10\n",
      "12000/12000 [==============================] - 50s 4ms/step - loss: 9.1800e-04 - acc: 0.9999 - val_loss: 3.2586e-06 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 1.00000\n",
      "CNN Error: 0.00%\n"
     ]
    }
   ],
   "source": [
    "model, callbacks_list = keras_model(image_x, image_y)\n",
    "model.fit(X_train, train_y, validation_data=(X_test, test_y), epochs=10, batch_size=64,callbacks=callbacks_list)\n",
    "scores = model.evaluate(X_test, test_y, verbose=0)\n",
    "print(\"CNN Error: %.2f%%\" % (100 - scores[1] * 100))\n",
    "\n",
    "model.save('emojinator.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
